# Server settings
HOST=localhost
PORT=8050
TRANSPORT=streamable-http # sse or streamable-http or stdio

# Client settings
MODEL=openai/gpt-oss-120b #llama-3.1-8b-instant or llama-3.3-70b-versatile or moonshotai/kimi-k2-instruct or openai/gpt-oss-120 or bopenai/gpt-oss-20b

# Optional settings
DEBUG=false
LOG_LEVEL=INFO
REQUEST_TIMEOUT=30

PRINT_ALL_MODEL_OUTPUT=True # Print all model output to console (useful for debugging)
GPT_OSS_REASONING=medium

GROQ_API_KEY=YOUR_GROQ_API_KEY
BRAVE_API_KEY=YOUR_BRAVE_API_KEY